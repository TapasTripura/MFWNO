{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# It trains MF-DeepONet for 2D time dependent Allen Cahn equation\n",
    "### HF data size = 20 samples, with 50 time steps 1000 points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ce-T3Tu5zyE4"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import *\n",
    "\n",
    "from timeit import default_timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "8JbWtxniSerT"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cbC_I56c-bb3"
   },
   "source": [
    "# DeepONet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "R08jMzYL-kLX"
   },
   "outputs": [],
   "source": [
    "class Deeponet(nn.Module):\n",
    "    def __init__(self, branchnet, trunknetdepth, width, space_dim):\n",
    "        super(Deeponet, self).__init__()\n",
    "\n",
    "        s_dim = space_dim\n",
    "        tlayers = []\n",
    "        blayers = [] \n",
    "        for i in range(len(branchnet)-2):\n",
    "            blayers.append(nn.Conv3d(branchnet[i],branchnet[i+1],kernel_size=3,stride=2)) \n",
    "            blayers.append(nn.ReLU(inplace=True))\n",
    "        blayers.append(nn.Conv3d(branchnet[-2],branchnet[-1],kernel_size=2,stride=2)) \n",
    "        blayers.append(nn.ReLU(inplace=True))\n",
    "        blayers.append(nn.Flatten())\n",
    "        blayers.append(nn.Linear(80,width))\n",
    "        \n",
    "        for i in range(trunknetdepth):\n",
    "            tlayers.append(nn.Linear(s_dim,width)) \n",
    "            tlayers.append(nn.ReLU(inplace=True))\n",
    "            s_dim = width\n",
    "        \n",
    "        self.branchnet = nn.Sequential(*blayers)\n",
    "        self.trunknet = nn.Sequential(*tlayers)\n",
    "        self.bias = nn.Linear(1,1)\n",
    "  \n",
    "    def hadprodsum(self, branch, trunk):\n",
    "        return torch.einsum(\"ij,ij->i\", branch, trunk)\n",
    "\n",
    "    def forward(self, xb, xt):\n",
    "        x1 = self.branchnet(xb)\n",
    "        x2 = self.trunknet(xt)\n",
    "        x  = self.hadprodsum(x1,x2)\n",
    "        x = x.view(-1,1)\n",
    "        x  = self.bias(x)      \n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PYbWdZMv-wLM"
   },
   "source": [
    "# Training and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "gPYxG-gG-1Sm"
   },
   "outputs": [],
   "source": [
    "ntrain = 20\n",
    "ntest = 1\n",
    "nreliability = 2000\n",
    "ntotal = ntrain + ntest\n",
    "epochs = 50\n",
    "lst = ntrain\n",
    "batch_size = 100\n",
    "side = 65\n",
    "\n",
    "n_total = ntrain + ntest\n",
    "learning_rate = 0.001\n",
    "\n",
    "r = 6\n",
    "s = int(side/r) + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 65\n"
     ]
    }
   ],
   "source": [
    "s = int(side/r) + 1\n",
    "# s = 13\n",
    "\n",
    "r_test = 1\n",
    "s_test = side\n",
    "print(s, s_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "MVQq4kzcRcd3"
   },
   "outputs": [],
   "source": [
    "path = 'data/ac2dlowhighres_1.mat'\n",
    "reader = MatReader(path)\n",
    "u_low = np.array(reader.read_field('ulr_nextstep'))\n",
    "u_high = np.array(reader.read_field('uhr'))\n",
    "x_coord, y_coord, t_coord = np.meshgrid( reader.read_field('x')[:, ::r], reader.read_field('y')[:, ::r], reader.read_field('time') )\n",
    "time = reader.read_field('time')\n",
    "\n",
    "x_coord_test, y_coord_test, t_coord_test = np.meshgrid( reader.read_field('x'), reader.read_field('y'), reader.read_field('time') )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 50, 65, 65) (4000, 51, 65, 65)\n"
     ]
    }
   ],
   "source": [
    "print(u_low.shape, u_high.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6050, 3)\n",
      "(211250, 3)\n"
     ]
    }
   ],
   "source": [
    "coords = np.stack((x_coord[..., :50].flatten(), y_coord[..., :50].flatten(), t_coord[..., :50].flatten()), axis=-1)\n",
    "print(coords.shape)\n",
    "\n",
    "coords_test = np.stack((x_coord_test[..., :50].flatten(), y_coord_test[..., :50].flatten(), t_coord_test[..., :50].flatten()), axis=-1)\n",
    "print(coords_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "ssqgRORpmAi9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 50, 11, 11) (20, 50, 11, 11) (20, 50, 11, 11) (1, 50, 65, 65) (1, 50, 65, 65)\n"
     ]
    }
   ],
   "source": [
    "x_or_h = u_high[:ntrain,:-1, ::r,::r] \n",
    "y_or_h = u_high[:ntrain,1:, ::r,::r] \n",
    "y_or_l = u_low[:ntrain, :, ::r, ::r] \n",
    "\n",
    "x_or_h_test_r = u_high[:ntest,:-1, ::r,::r] \n",
    "y_or_l_test_r = u_low[:ntest, :, ::r, ::r] \n",
    "\n",
    "y_or_h_test = u_high[:ntest, 1:,::r_test, ::r_test] \n",
    "y_or_l_test = u_low[:ntest, :, ::r_test, ::r_test] \n",
    "\n",
    "print(x_or_h.shape, y_or_h.shape, y_or_l.shape, y_or_h_test.shape, y_or_l_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "4onNBYRynjIa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 50, 11, 11, 2) (20, 50, 11, 11) (1, 50, 11, 11, 2) (1, 50, 65, 65)\n"
     ]
    }
   ],
   "source": [
    "# Create the input and output (residual) dataset\n",
    "x_mf = np.stack((x_or_h, y_or_l), axis=-1)\n",
    "y_mf = y_or_h - y_or_l.reshape((ntrain,time.shape[1]-1,s,s))\n",
    "\n",
    "x_mf_test = np.stack((x_or_h_test_r, y_or_l_test_r), axis=-1)\n",
    "y_mf_test = y_or_h_test - y_or_l_test.reshape((ntest,time.shape[1]-1,s_test,s_test))\n",
    "\n",
    "print(x_mf.shape, y_mf.shape, x_mf_test.shape, y_mf_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 2, 50, 11, 11) (20, 50, 11, 11) (1, 2, 50, 11, 11) (1, 50, 65, 65)\n"
     ]
    }
   ],
   "source": [
    "# Split the training and testing datasets\n",
    "xb_train_mf, y_train_mf = x_mf[:ntrain, ...].transpose(0,4,1,2,3), y_mf[:ntrain, ...] \n",
    "xb_test_mf, y_test_mf = x_mf_test[:ntest, ...].transpose(0,4,1,2,3), y_mf_test[:ntest, ...] \n",
    "\n",
    "print(xb_train_mf.shape, y_train_mf.shape, xb_test_mf.shape, y_test_mf.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data:\n",
    "xb_train_mf  = np.repeat(xb_train_mf.astype(np.float32), coords.shape[0], axis=0)\n",
    "xt_train_mf =  np.tile(coords.astype(np.float32), (ntrain,1))\n",
    "y_train_mf  =  y_train_mf.astype(np.float32).reshape(-1,1)\n",
    "\n",
    "xb_test_mf  = np.repeat(xb_test_mf.astype(np.float32), coords_test.shape[0], axis=0)\n",
    "xt_test_mf =  np.tile(coords_test.astype(np.float32), (ntest,1))\n",
    "y_test_mf  =  y_test_mf.astype(np.float32).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(121000, 2, 50, 11, 11) (121000, 3) (121000, 1) (211250, 2, 50, 11, 11) (211250, 3) (211250, 1)\n"
     ]
    }
   ],
   "source": [
    "print(xb_train_mf.shape, xt_train_mf.shape, y_train_mf.shape, xb_test_mf.shape, xt_test_mf.shape, y_test_mf.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Rhzgcb4IRZaw"
   },
   "outputs": [],
   "source": [
    "# Define the dataloaders\n",
    "\n",
    "xb_train_mf = torch.from_numpy(xb_train_mf)\n",
    "xt_train_mf = torch.from_numpy(xt_train_mf)\n",
    "xb_test_mf = torch.from_numpy(xb_test_mf)\n",
    "xt_test_mf = torch.from_numpy(xt_test_mf)\n",
    "y_train_mf = torch.from_numpy(y_train_mf)\n",
    "y_test_mf = torch.from_numpy(y_test_mf)\n",
    "\n",
    "train_loader_mf = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(xb_train_mf, xt_train_mf, y_train_mf),\n",
    "                                              batch_size=batch_size, shuffle=True)\n",
    "test_loader_mf = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(xb_test_mf, xt_test_mf, y_test_mf),\n",
    "                                             batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s-31oJvWVHO-"
   },
   "source": [
    "# MF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1680492744027,
     "user": {
      "displayName": "CSCCM IITD",
      "userId": "18000198353382878931"
     },
     "user_tz": 240
    },
    "id": "siHHykHz-2ND",
    "outputId": "fe4e405e-1358-46cd-fa14-945050b4d853"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21390\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "# bdepth = 3\n",
    "blayers = [xb_train_mf.shape[1], 16, 32, 16]\n",
    "tdepth = 3\n",
    "width = 20\n",
    "\n",
    "inputsizeb = xb_train_mf.shape[-1]\n",
    "spdim = xt_train_mf.shape[-1]\n",
    "\n",
    "model = Deeponet(blayers, tdepth, width, spdim).cuda()\n",
    "\n",
    "# if trained model is already available\n",
    "# model = torch.load('model/deeponet_Allen_Cahn_10')\n",
    "\n",
    "print(count_params(model))\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 336152,
     "status": "error",
     "timestamp": 1680493081409,
     "user": {
      "displayName": "CSCCM IITD",
      "userId": "18000198353382878931"
     },
     "user_tz": 240
    },
    "id": "RuP6QIZt-5Ag",
    "outputId": "3dbce736-a909-40df-a93f-693034023386",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, time_taken: 21.727362303994596, train_mse: 0.006339156749987329,test_mse: 0.00591062257464002\n",
      "epoch 1, time_taken: 19.473189159994945, train_mse: 0.0030183341871807064,test_mse: 0.0058127859615203685\n",
      "epoch 2, time_taken: 20.345944190165028, train_mse: 0.0029975507919080577,test_mse: 0.005816880777217675\n",
      "epoch 3, time_taken: 20.117357693146914, train_mse: 0.0029691137477535707,test_mse: 0.005796475022720996\n",
      "epoch 4, time_taken: 19.81907417019829, train_mse: 0.002936429219205685,test_mse: 0.005795304217684883\n",
      "epoch 5, time_taken: 20.163219870999455, train_mse: 0.002936152902526554,test_mse: 0.006400909321867476\n",
      "epoch 6, time_taken: 17.878504429012537, train_mse: 0.0029080599777158525,test_mse: 0.005832636065737619\n",
      "epoch 7, time_taken: 18.738379662157968, train_mse: 0.002888157828834845,test_mse: 0.006147619090369996\n",
      "epoch 8, time_taken: 17.760732654947788, train_mse: 0.0028656935792422105,test_mse: 0.005889427847306297\n",
      "epoch 9, time_taken: 19.04607144300826, train_mse: 0.002844361054014957,test_mse: 0.005841173842499794\n",
      "epoch 10, time_taken: 19.11729478603229, train_mse: 0.0028377736817245865,test_mse: 0.005838056718862146\n",
      "epoch 11, time_taken: 18.962648489046842, train_mse: 0.002823699765540669,test_mse: 0.0058193201382705055\n",
      "epoch 12, time_taken: 18.210713784908876, train_mse: 0.002820001438329591,test_mse: 0.005837485654096345\n",
      "epoch 13, time_taken: 18.685828431043774, train_mse: 0.0028049764646244165,test_mse: 0.005798144992950841\n",
      "epoch 14, time_taken: 18.719014389207587, train_mse: 0.0028075690260965162,test_mse: 0.0058754230672831585\n",
      "epoch 15, time_taken: 18.14580639009364, train_mse: 0.0027948090393617674,test_mse: 0.005789501002117531\n",
      "epoch 16, time_taken: 18.09909511404112, train_mse: 0.0027875171651272875,test_mse: 0.005790319015236619\n",
      "epoch 17, time_taken: 17.422670810949057, train_mse: 0.002775806788645429,test_mse: 0.0057978754572927645\n",
      "epoch 18, time_taken: 18.40765318600461, train_mse: 0.0027695973480179473,test_mse: 0.005792577408706103\n",
      "epoch 19, time_taken: 19.015659573022276, train_mse: 0.002769470205697691,test_mse: 0.005795450921535582\n",
      "epoch 20, time_taken: 20.58175858296454, train_mse: 0.002765818732647054,test_mse: 0.005785978831373888\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m train_l2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m xb,xt, y \u001b[38;5;129;01min\u001b[39;00m train_loader_mf:\n\u001b[0;32m----> 7\u001b[0m     xb,xt, y \u001b[38;5;241m=\u001b[39m xb\u001b[38;5;241m.\u001b[39mcuda(), xt\u001b[38;5;241m.\u001b[39mcuda(), y\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[1;32m      9\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     10\u001b[0m     out \u001b[38;5;241m=\u001b[39m model(xb, xt)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for ep in range(epochs):\n",
    "    model.train()\n",
    "    t1 = default_timer()\n",
    "    train_mse = 0\n",
    "    train_l2 = 0\n",
    "    for xb,xt, y in train_loader_mf:\n",
    "        xb,xt, y = xb.cuda(), xt.cuda(), y.cuda()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        out = model(xb, xt)\n",
    "\n",
    "        mse = F.mse_loss(out.view(out.shape[0], -1), y.view(out.shape[0], -1), reduction='mean')\n",
    "        mse.backward() # use the l2 relative loss\n",
    "\n",
    "        optimizer.step()\n",
    "        train_mse += mse.item()\n",
    "\n",
    "    model.eval()\n",
    "    test_mse = 0\n",
    "    with torch.no_grad():\n",
    "        for xb,xt, y in test_loader_mf:\n",
    "            xb,xt, y = xb.cuda(), xt.cuda(), y.cuda()\n",
    "\n",
    "            out = model(xb, xt)\n",
    "            tmse = F.mse_loss(out.view(out.shape[0], -1), y.view(out.shape[0], -1), reduction='mean')\n",
    "            test_mse += tmse.item()\n",
    "\n",
    "    train_mse /= len(train_loader_mf)\n",
    "    test_mse /= len(test_loader_mf)\n",
    "    t2 = default_timer()\n",
    "    print(f'epoch {ep}, time_taken: {t2-t1}, train_mse: {train_mse},test_mse: {test_mse}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the MF-DeepONet model\n",
    "\n",
    "# torch.save(model, 'model/deeponet_Allen_Cahn_10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the training is done, delete some variables for memory\n",
    "del xb_train_mf, xt_train_mf, y_train_mf, xb_test_mf, xt_test_mf, y_test_mf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 2\n",
    "data_range = np.arange(0,nreliability,batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pCujdZ_PT4Vl",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Prediction:\n",
    "pred_mf = [] \n",
    "actual = []\n",
    "\n",
    "for i in range(len(data_range)):\n",
    "    print('Data_range-{}'.format(i))\n",
    "\n",
    "    x_or_h_test_r = u_high[data_range[i]:data_range[i]+batch,:-1, ::r,::r] \n",
    "    y_or_l_test_r = u_low[data_range[i]:data_range[i]+batch, :, ::r, ::r] \n",
    "    y_or_h_test = u_high[data_range[i]:data_range[i]+batch, 1:,::r_test, ::r_test] \n",
    "    y_or_l_test = u_low[data_range[i]:data_range[i]+batch, :, ::r_test, ::r_test] \n",
    "\n",
    "    # Create the input and output (residual) dataset\n",
    "    x_mf_test = np.stack((x_or_h_test_r, y_or_l_test_r), axis=-1)\n",
    "    y_test_mf = y_or_h_test - y_or_l_test.reshape((batch,time.shape[1]-1,s_test,s_test))\n",
    "\n",
    "    # Split the training and testing datasets\n",
    "    xb_test_mf = x_mf_test.transpose(0,4,1,2,3) \n",
    "\n",
    "    xb_test_mf  = np.repeat(xb_test_mf.astype(np.float32), coords_test.shape[0], axis=0)\n",
    "    xt_test_mf =  np.tile(coords_test.astype(np.float32), (batch,1))\n",
    "    y_test_mf  =  y_test_mf.astype(np.float32).reshape(-1,1)\n",
    "\n",
    "    # Define the dataloaders\n",
    "    xb_test_mf = torch.from_numpy(xb_test_mf)\n",
    "    xt_test_mf = torch.from_numpy(xt_test_mf)\n",
    "    y_test_mf = torch.from_numpy(y_test_mf)\n",
    "    \n",
    "    test_loader_mf = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(xb_test_mf, xt_test_mf, y_test_mf),\n",
    "                                                 batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        index = 0\n",
    "        for xb, xt, y in test_loader_mf:\n",
    "            tmse = 0\n",
    "            xb, xt, y = xb.cuda(), xt.cuda(), y.cuda()\n",
    "    \n",
    "            out = model(xb, xt)\n",
    "            tmse = F.mse_loss(out.view(out.shape[0], -1), y.view(out.shape[0], -1), reduction='mean').item()\n",
    "    \n",
    "            pred_mf.append( out.cpu() )\n",
    "            actual.append( y.cpu() )\n",
    "            # print(\"Data-Range-{}, Batch-{}, Test-loss-{:0.6f}\".format( data_range[i], index, tmse ))\n",
    "            index += 1\n",
    "    \n",
    "actual = torch.cat(( actual ))\n",
    "pred_mf = torch.cat(( pred_mf ))\n",
    "print('Mean mse_mf-{}'.format(F.mse_loss(actual, pred_mf).item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_mf = pred_mf.reshape(nreliability, s, s)\n",
    "actual = actual.reshape(nreliability, s, s)\n",
    "\n",
    "print(pred_mf.shape, actual.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F-ELXZMPT7K_"
   },
   "outputs": [],
   "source": [
    "# Add the residual operator to LF-dataset \n",
    "\n",
    "real_mf = y_test_mf.reshape(ntest,50,s,s) + u_low \n",
    "output_mf = pred_mf.reshape(ntest,50,s,s) + u_low \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(real_mf.shape, output_mf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_mf.reshape(ntest, 50, 17, 17).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_mf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wu0WJf6wT8lu"
   },
   "outputs": [],
   "source": [
    "mse_pred = F.mse_loss(output_mf, real_mf).item()\n",
    "mse_LF = F.mse_loss(real_mf, torch.from_numpy(x_mf[-ntest:, ..., 1])).item()\n",
    "mse_residual = F.mse_loss(y_test_mf, pred_mf)\n",
    "\n",
    "print('MSE-Predicted solution-{:0.4f}, MSE-LF Data-{:0.4f}, MSE-Residual-{:0.4f}'\n",
    "      .format(mse_pred, mse_LF, mse_residual))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 10524,
     "status": "ok",
     "timestamp": 1680493128514,
     "user": {
      "displayName": "CSCCM IITD",
      "userId": "18000198353382878931"
     },
     "user_tz": 240
    },
    "id": "T6UkMuPyUTPP",
    "outputId": "00f7dee6-7808-4e25-cca1-cb4281dfd879"
   },
   "outputs": [],
   "source": [
    "fig4, axs = plt.subplots(nrows=3, ncols=5, figsize=(16, 6), facecolor='w', edgecolor='k')\n",
    "fig4.subplots_adjust(hspace=0.35, wspace=0.2)\n",
    "\n",
    "fig4.suptitle(f'Predictions MFWNO AC2d Size', fontsize=16)\n",
    "sample = 0\n",
    "index = 0 \n",
    "for i in range(50):\n",
    "    if i % 10 == 0:\n",
    "        im = axs[0, index].imshow(real_mf[sample, i, :, :], cmap='jet', vmin=-1, vmax=1)\n",
    "        plt.colorbar(im, ax=axs[0, index])\n",
    "        im = axs[1, index].imshow(output_mf[sample, i, :, :], cmap='jet', vmin=-1, vmax=1)\n",
    "        plt.colorbar(im, ax=axs[1, index])\n",
    "        im = axs[2, index].imshow(torch.abs(real_mf[sample, i, :, :] - output_mf[sample, i, :, :]),\n",
    "                                    cmap='jet')\n",
    "        plt.colorbar(im, ax=axs[2, index])\n",
    "        index += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOjZCU0Za7/TgYeQCK7zD4/",
   "machine_shape": "hm",
   "provenance": [
    {
     "file_id": "1tX2GWAJczeMcQh_sQxxRE7l2iqTVgQiI",
     "timestamp": 1657707119891
    },
    {
     "file_id": "1dZDsY9GN11KWInJ5P2lGu5cjpube9Pyk",
     "timestamp": 1657558949607
    },
    {
     "file_id": "1Ms71XMkjtfE4Dk8XWfNwqcdRJpeWvC2Q",
     "timestamp": 1656413318405
    },
    {
     "file_id": "1fXGQRqGH0Sjj6hvnVQWF5aFAR7Kzbncs",
     "timestamp": 1656412090942
    },
    {
     "file_id": "1OPIb4ygLODwEKnHrahQ__DiDVyCq6543",
     "timestamp": 1656351883644
    }
   ]
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
