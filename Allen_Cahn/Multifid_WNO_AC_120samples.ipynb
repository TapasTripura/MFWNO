{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# It trains MF-WNO for 2D time dependent Allen Cahn equation\n",
    "### HF data size = 120 samples, with 50 time steps 6000 points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ce-T3Tu5zyE4"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.parameter import Parameter\n",
    "torch.cuda.empty_cache()\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import *\n",
    "\n",
    "from timeit import default_timer\n",
    "from pytorch_wavelets import DWT, IDWT # (or import DWT, IDWT)\n",
    "from pytorch_wavelets import DTCWTForward, DTCWTInverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8JbWtxniSerT"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cbC_I56c-bb3"
   },
   "source": [
    "# WNO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R08jMzYL-kLX"
   },
   "outputs": [],
   "source": [
    "class WaveConv2dCwt(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, level, size, wavelet1, wavelet2):\n",
    "        super(WaveConv2dCwt, self).__init__()\n",
    "\n",
    "        \"\"\"\n",
    "        2D Wavelet layer. It does DWT, linear transform, and Inverse dWT. \n",
    "        !! It is computationally expensive than the discrete \"WaveConv2d\" !!\n",
    "        \"\"\"\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.level = level\n",
    "        self.wavelet_level1 = wavelet1\n",
    "        self.wavelet_level2 = wavelet2        \n",
    "        dummy_data = torch.randn( 1,1,*size ) \n",
    "        dwt_ = DTCWTForward(J=self.level, biort=self.wavelet_level1,\n",
    "                            qshift=self.wavelet_level2)\n",
    "        mode_data, mode_coef = dwt_(dummy_data)\n",
    "        self.modes1 = mode_data.shape[-2]\n",
    "        self.modes2 = mode_data.shape[-1]\n",
    "        self.modes21 = mode_coef[-1].shape[-3]\n",
    "        self.modes22 = mode_coef[-1].shape[-2]\n",
    "        \n",
    "        # Parameter initilization\n",
    "        self.scale = (1 / (in_channels * out_channels))\n",
    "        self.weights0 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2))\n",
    "        self.weights15r = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes21, self.modes22))\n",
    "        self.weights15c = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes21, self.modes22))\n",
    "        self.weights45r = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes21, self.modes22))\n",
    "        self.weights45c = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes21, self.modes22))\n",
    "        self.weights75r = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes21, self.modes22))\n",
    "        self.weights75c = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes21, self.modes22))\n",
    "        self.weights105r = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes21, self.modes22))\n",
    "        self.weights105c = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes21, self.modes22))\n",
    "        self.weights135r = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes21, self.modes22))\n",
    "        self.weights135c = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes21, self.modes22))\n",
    "        self.weights165r = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes21, self.modes22))\n",
    "        self.weights165c = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes21, self.modes22))\n",
    "\n",
    "    # Convolution\n",
    "    def mul2d(self, input, weights):\n",
    "        # (batch, in_channel, x,y ), (in_channel, out_channel, x,y) -> (batch, out_channel, x,y)\n",
    "        return torch.einsum(\"bixy,ioxy->boxy\", input, weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Input parameters: \n",
    "        -----------------\n",
    "        x : tensor, shape-[Batch * Channel * x * y]\n",
    "        Output parameters: \n",
    "        ------------------\n",
    "        x : tensor, shape-[Batch * Channel * x * y]\n",
    "        \"\"\"        \n",
    "        # Compute dual tree continuous Wavelet coefficients \n",
    "        cwt = DTCWTForward(J=self.level, biort=self.wavelet_level1, qshift=self.wavelet_level2).to(x.device)\n",
    "        x_ft, x_coeff = cwt(x)\n",
    "        \n",
    "        out_ft = torch.zeros_like(x_ft, device= x.device)\n",
    "        out_coeff = [torch.zeros_like(coeffs, device= x.device) for coeffs in x_coeff]\n",
    "        \n",
    "        # Multiply the final approximate Wavelet modes\n",
    "        out_ft = self.mul2d(x_ft[:, :, :self.modes1, :self.modes2], self.weights0)\n",
    "        # Multiply the final detailed wavelet coefficients        \n",
    "        out_coeff[-1][:,:,0,:,:,0] = self.mul2d(x_coeff[-1][:,:,0,:,:,0].clone(), self.weights15r)\n",
    "        out_coeff[-1][:,:,0,:,:,1] = self.mul2d(x_coeff[-1][:,:,0,:,:,1].clone(), self.weights15c)\n",
    "        out_coeff[-1][:,:,1,:,:,0] = self.mul2d(x_coeff[-1][:,:,1,:,:,0].clone(), self.weights45r)\n",
    "        out_coeff[-1][:,:,1,:,:,1] = self.mul2d(x_coeff[-1][:,:,1,:,:,1].clone(), self.weights45c)\n",
    "        out_coeff[-1][:,:,2,:,:,0] = self.mul2d(x_coeff[-1][:,:,2,:,:,0].clone(), self.weights75r)\n",
    "        out_coeff[-1][:,:,2,:,:,1] = self.mul2d(x_coeff[-1][:,:,2,:,:,1].clone(), self.weights75c)\n",
    "        out_coeff[-1][:,:,3,:,:,0] = self.mul2d(x_coeff[-1][:,:,3,:,:,0].clone(), self.weights105r)\n",
    "        out_coeff[-1][:,:,3,:,:,1] = self.mul2d(x_coeff[-1][:,:,3,:,:,1].clone(), self.weights105c)\n",
    "        out_coeff[-1][:,:,4,:,:,0] = self.mul2d(x_coeff[-1][:,:,4,:,:,0].clone(), self.weights135r)\n",
    "        out_coeff[-1][:,:,4,:,:,1] = self.mul2d(x_coeff[-1][:,:,4,:,:,1].clone(), self.weights135c)\n",
    "        out_coeff[-1][:,:,5,:,:,0] = self.mul2d(x_coeff[-1][:,:,5,:,:,0].clone(), self.weights165r)\n",
    "        out_coeff[-1][:,:,5,:,:,1] = self.mul2d(x_coeff[-1][:,:,5,:,:,1].clone(), self.weights165c)\n",
    "        \n",
    "        # Return to physical space        \n",
    "        icwt = DTCWTInverse(biort=self.wavelet_level1, qshift=self.wavelet_level2).to(x.device)\n",
    "        x = icwt((out_ft, out_coeff))\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zpeJTDt3-kyO"
   },
   "outputs": [],
   "source": [
    "class WNO2d(nn.Module):\n",
    "    def __init__(self, width, level, size, wavelet, in_channel, grid_range):\n",
    "        super(WNO2d, self).__init__()\n",
    "\n",
    "        \"\"\"\n",
    "        The WNO network. It contains 4 layers of the Wavelet integral layer.\n",
    "        1. Lift the input using v(x) = self.fc0 .\n",
    "        2. 4 layers of the integral operators v(+1) = g(K(.) + W)(v).\n",
    "            W is defined by self.w_; K is defined by self.conv_.\n",
    "        3. Project the output of last layer using self.fc1 and self.fc2.\n",
    "        \n",
    "        input: the solution of the coefficient function and locations (a(x, y), x, y)\n",
    "        input shape: (batchsize, x=s, y=s, c=3)\n",
    "        output: the solution \n",
    "        output shape: (batchsize, x=s, y=s, c=1)\n",
    "        \"\"\"\n",
    "\n",
    "        self.level = level\n",
    "        self.width = width\n",
    "        self.size = size\n",
    "        self.wavelet1 = wavelet[0]\n",
    "        self.wavelet2 = wavelet[1]\n",
    "        self.in_channel = in_channel\n",
    "        self.grid_range = grid_range \n",
    "        self.padding = 1\n",
    "        \n",
    "        self.fc0 = nn.Linear(self.in_channel, self.width) # input channel is 3: (a(x, y), x, y)\n",
    "\n",
    "        self.conv0 = WaveConv2dCwt(self.width, self.width, self.level, self.size,\n",
    "                                            self.wavelet1, self.wavelet2)\n",
    "        self.conv1 = WaveConv2dCwt(self.width, self.width, self.level, self.size,\n",
    "                                            self.wavelet1, self.wavelet2)\n",
    "        self.conv2 = WaveConv2dCwt(self.width, self.width, self.level, self.size,\n",
    "                                            self.wavelet1, self.wavelet2)\n",
    "        self.w0 = nn.Conv2d(self.width, self.width, 1)\n",
    "        self.w1 = nn.Conv2d(self.width, self.width, 1)\n",
    "        self.w2 = nn.Conv2d(self.width, self.width, 1)\n",
    "\n",
    "        self.fc1 = nn.Linear(self.width, 128)\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        grid = self.get_grid(x.shape, x.device)\n",
    "        x = torch.cat((x, grid), dim=-1)\n",
    "\n",
    "        x = self.fc0(x)\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "        if self.padding != 0:\n",
    "            x = F.pad(x, [0,self.padding, 0,self.padding]) \n",
    "        \n",
    "        # pdb.set_trace()\n",
    "        x1 = self.conv0(x)\n",
    "        x2 = self.w0(x)\n",
    "        x = x1 + x2\n",
    "        x = F.gelu(x)\n",
    "\n",
    "        x1 = self.conv1(x)\n",
    "        x2 = self.w1(x)\n",
    "        x = x1 + x2\n",
    "        x = F.gelu(x)\n",
    "\n",
    "        x1 = self.conv2(x)\n",
    "        x2 = self.w2(x)\n",
    "        x = x1 + x2\n",
    "\n",
    "        if self.padding != 0:\n",
    "            x = x[..., :-self.padding, :-self.padding]\n",
    "        x = x.permute(0, 2, 3, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.gelu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "    def get_grid(self, shape, device):\n",
    "        # The grid of the solution\n",
    "        batchsize, size_x, size_y = shape[0], shape[1], shape[2]\n",
    "        gridx = torch.tensor(np.linspace(0, self.grid_range[0], size_x), dtype=torch.float)\n",
    "        gridx = gridx.reshape(1, size_x, 1, 1).repeat([batchsize, 1, size_y, 1])\n",
    "        gridy = torch.tensor(np.linspace(0, self.grid_range[1], size_y), dtype=torch.float)\n",
    "        gridy = gridy.reshape(1, 1, size_y, 1).repeat([batchsize, size_x, 1, 1])\n",
    "        return torch.cat((gridx, gridy), dim=-1).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PYbWdZMv-wLM"
   },
   "source": [
    "# Training and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gPYxG-gG-1Sm"
   },
   "outputs": [],
   "source": [
    "ntrain = 6000\n",
    "ntest = 1000\n",
    "ntotal = ntrain + ntest\n",
    "epochs = 300\n",
    "lst = ntrain\n",
    "batch_size = 100\n",
    "side = 65\n",
    "\n",
    "n_total = ntrain + ntest\n",
    "learning_rate = 0.001\n",
    "\n",
    "step_size = 40\n",
    "gamma = 0.5\n",
    "\n",
    "wavelet = ['near_sym_a', 'qshift_a']  # wavelet basis function\n",
    "level = 2        # lavel of wavelet decomposition\n",
    "width = 32       # uplifting dimension\n",
    "s = side\n",
    "grid_range = [1, 1]\n",
    "in_channel = 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MVQq4kzcRcd3"
   },
   "outputs": [],
   "source": [
    "path = 'data/ac2dlowhighres_1.mat'\n",
    "reader = MatReader(path)\n",
    "u_low = np.array(reader.read_field('ulr_nextstep')[:(ntotal//50)])\n",
    "u_high = np.array(reader.read_field('uhr')[:(ntotal//50)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(u_low.shape, u_high.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ssqgRORpmAi9"
   },
   "outputs": [],
   "source": [
    "x_or_h = u_high[:,:-1,:,:].reshape(-1,s,s,1)\n",
    "y_or_h = u_high[:,1:,:,:].reshape(-1,s,s)\n",
    "y_or_l = u_low.reshape(-1,s,s,1)\n",
    "\n",
    "print(x_or_h.shape, y_or_h.shape, y_or_l.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4onNBYRynjIa"
   },
   "outputs": [],
   "source": [
    "# Create the input and output (residual) dataset\n",
    "\n",
    "x_mf = np.concatenate((x_or_h,y_or_l),axis=-1)\n",
    "y_mf = y_or_h - y_or_l.reshape((n_total,s,s))\n",
    "\n",
    "x_mf = torch.tensor( x_mf, dtype=torch.float ) \n",
    "y_mf = torch.tensor( y_mf, dtype=torch.float ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = torch.Generator().manual_seed(453)\n",
    "dataset = torch.utils.data.random_split(torch.utils.data.TensorDataset(x_mf, y_mf),\n",
    "                                    [ntrain, ntest], generator=generator)\n",
    "train_data, test_data = dataset[0], dataset[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j0rQJiB1S0Hb"
   },
   "outputs": [],
   "source": [
    "# Split the training and testing datasets\n",
    "\n",
    "x_train_mf, y_train_mf = train_data[:][0], train_data[:][1]\n",
    "x_test_mf, y_test_mf = test_data[:][0], test_data[:][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_mf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rhzgcb4IRZaw"
   },
   "outputs": [],
   "source": [
    "# Define the dataloaders\n",
    "\n",
    "train_loader_mf = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(x_train_mf, y_train_mf),\n",
    "                                           batch_size=batch_size, shuffle=True)\n",
    "test_loader_mf = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(x_test_mf, y_test_mf),\n",
    "                                              batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1680492744027,
     "user": {
      "displayName": "CSCCM IITD",
      "userId": "18000198353382878931"
     },
     "user_tz": 240
    },
    "id": "siHHykHz-2ND",
    "outputId": "fe4e405e-1358-46cd-fa14-945050b4d853"
   },
   "outputs": [],
   "source": [
    "# %%\n",
    "\"\"\" The MD-WNO model definition \"\"\"\n",
    "model_mf = WNO2d(width=width, level=level, size=[s,s], wavelet=wavelet,\n",
    "              in_channel=in_channel, grid_range=grid_range).to(device)\n",
    "print(count_params(model_mf))\n",
    "\n",
    "optimizer = torch.optim.Adam(model_mf.parameters(), lr=learning_rate, weight_decay=1e-6)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s-31oJvWVHO-"
   },
   "source": [
    "# MF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 336152,
     "status": "error",
     "timestamp": 1680493081409,
     "user": {
      "displayName": "CSCCM IITD",
      "userId": "18000198353382878931"
     },
     "user_tz": 240
    },
    "id": "RuP6QIZt-5Ag",
    "outputId": "3dbce736-a909-40df-a93f-693034023386",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch-111, Time-56.1741, Train-MSE-0.0025, Train-L2-0.0581, Test-L2-0.0663\n",
      "Epoch-112, Time-54.7149, Train-MSE-0.0025, Train-L2-0.0580, Test-L2-0.0629\n",
      "Epoch-113, Time-55.5034, Train-MSE-0.0025, Train-L2-0.0580, Test-L2-0.0669\n",
      "Epoch-114, Time-53.3029, Train-MSE-0.0025, Train-L2-0.0578, Test-L2-0.0624\n",
      "Epoch-115, Time-55.3826, Train-MSE-0.0025, Train-L2-0.0574, Test-L2-0.0660\n",
      "Epoch-116, Time-54.6351, Train-MSE-0.0025, Train-L2-0.0576, Test-L2-0.0630\n",
      "Epoch-117, Time-53.0871, Train-MSE-0.0025, Train-L2-0.0575, Test-L2-0.0656\n",
      "Epoch-118, Time-53.1052, Train-MSE-0.0025, Train-L2-0.0574, Test-L2-0.0641\n",
      "Epoch-119, Time-53.5739, Train-MSE-0.0025, Train-L2-0.0573, Test-L2-0.0631\n",
      "Epoch-120, Time-52.1776, Train-MSE-0.0025, Train-L2-0.0550, Test-L2-0.0614\n",
      "Epoch-121, Time-52.2572, Train-MSE-0.0025, Train-L2-0.0548, Test-L2-0.0613\n",
      "Epoch-122, Time-51.3528, Train-MSE-0.0025, Train-L2-0.0547, Test-L2-0.0612\n",
      "Epoch-123, Time-47.2369, Train-MSE-0.0025, Train-L2-0.0547, Test-L2-0.0612\n",
      "Epoch-124, Time-48.0732, Train-MSE-0.0025, Train-L2-0.0546, Test-L2-0.0611\n",
      "Epoch-125, Time-50.8995, Train-MSE-0.0025, Train-L2-0.0546, Test-L2-0.0611\n",
      "Epoch-126, Time-47.5563, Train-MSE-0.0025, Train-L2-0.0545, Test-L2-0.0611\n",
      "Epoch-127, Time-50.5930, Train-MSE-0.0025, Train-L2-0.0545, Test-L2-0.0610\n",
      "Epoch-128, Time-48.2215, Train-MSE-0.0025, Train-L2-0.0544, Test-L2-0.0611\n",
      "Epoch-129, Time-47.8384, Train-MSE-0.0025, Train-L2-0.0544, Test-L2-0.0609\n",
      "Epoch-130, Time-47.6279, Train-MSE-0.0025, Train-L2-0.0544, Test-L2-0.0609\n",
      "Epoch-131, Time-48.9945, Train-MSE-0.0025, Train-L2-0.0543, Test-L2-0.0608\n",
      "Epoch-132, Time-50.4054, Train-MSE-0.0025, Train-L2-0.0543, Test-L2-0.0609\n",
      "Epoch-133, Time-47.2636, Train-MSE-0.0025, Train-L2-0.0542, Test-L2-0.0608\n",
      "Epoch-134, Time-46.5732, Train-MSE-0.0025, Train-L2-0.0542, Test-L2-0.0607\n",
      "Epoch-135, Time-45.8607, Train-MSE-0.0025, Train-L2-0.0542, Test-L2-0.0607\n",
      "Epoch-136, Time-45.6188, Train-MSE-0.0025, Train-L2-0.0542, Test-L2-0.0607\n",
      "Epoch-137, Time-46.1131, Train-MSE-0.0025, Train-L2-0.0541, Test-L2-0.0606\n",
      "Epoch-138, Time-46.0758, Train-MSE-0.0025, Train-L2-0.0541, Test-L2-0.0606\n",
      "Epoch-139, Time-45.6334, Train-MSE-0.0025, Train-L2-0.0541, Test-L2-0.0605\n",
      "Epoch-140, Time-45.3385, Train-MSE-0.0025, Train-L2-0.0543, Test-L2-0.0611\n",
      "Epoch-141, Time-45.2782, Train-MSE-0.0025, Train-L2-0.0543, Test-L2-0.0605\n",
      "Epoch-142, Time-45.6023, Train-MSE-0.0025, Train-L2-0.0542, Test-L2-0.0607\n",
      "Epoch-143, Time-45.7867, Train-MSE-0.0025, Train-L2-0.0543, Test-L2-0.0606\n",
      "Epoch-144, Time-45.6718, Train-MSE-0.0025, Train-L2-0.0541, Test-L2-0.0612\n",
      "Epoch-145, Time-45.7667, Train-MSE-0.0025, Train-L2-0.0544, Test-L2-0.0608\n",
      "Epoch-146, Time-46.2337, Train-MSE-0.0025, Train-L2-0.0540, Test-L2-0.0604\n",
      "Epoch-147, Time-45.9558, Train-MSE-0.0025, Train-L2-0.0541, Test-L2-0.0612\n",
      "Epoch-148, Time-45.6390, Train-MSE-0.0025, Train-L2-0.0543, Test-L2-0.0603\n",
      "Epoch-149, Time-45.8461, Train-MSE-0.0025, Train-L2-0.0537, Test-L2-0.0601\n",
      "Epoch-150, Time-45.7496, Train-MSE-0.0025, Train-L2-0.0538, Test-L2-0.0603\n",
      "Epoch-151, Time-46.1856, Train-MSE-0.0025, Train-L2-0.0541, Test-L2-0.0606\n",
      "Epoch-152, Time-46.1789, Train-MSE-0.0025, Train-L2-0.0539, Test-L2-0.0600\n",
      "Epoch-153, Time-45.6810, Train-MSE-0.0025, Train-L2-0.0538, Test-L2-0.0599\n",
      "Epoch-154, Time-45.8579, Train-MSE-0.0025, Train-L2-0.0537, Test-L2-0.0601\n",
      "Epoch-155, Time-46.1351, Train-MSE-0.0025, Train-L2-0.0538, Test-L2-0.0598\n",
      "Epoch-156, Time-45.7487, Train-MSE-0.0025, Train-L2-0.0534, Test-L2-0.0599\n",
      "Epoch-157, Time-45.5367, Train-MSE-0.0025, Train-L2-0.0537, Test-L2-0.0603\n",
      "Epoch-158, Time-45.6674, Train-MSE-0.0025, Train-L2-0.0534, Test-L2-0.0605\n",
      "Epoch-159, Time-45.8948, Train-MSE-0.0025, Train-L2-0.0538, Test-L2-0.0597\n",
      "Epoch-160, Time-45.8030, Train-MSE-0.0025, Train-L2-0.0527, Test-L2-0.0592\n",
      "Epoch-161, Time-45.6131, Train-MSE-0.0025, Train-L2-0.0526, Test-L2-0.0592\n",
      "Epoch-162, Time-45.5207, Train-MSE-0.0025, Train-L2-0.0526, Test-L2-0.0592\n",
      "Epoch-163, Time-45.6542, Train-MSE-0.0025, Train-L2-0.0526, Test-L2-0.0591\n",
      "Epoch-164, Time-45.8774, Train-MSE-0.0025, Train-L2-0.0525, Test-L2-0.0591\n",
      "Epoch-165, Time-45.8570, Train-MSE-0.0025, Train-L2-0.0525, Test-L2-0.0592\n",
      "Epoch-166, Time-45.6168, Train-MSE-0.0025, Train-L2-0.0525, Test-L2-0.0591\n",
      "Epoch-167, Time-45.5884, Train-MSE-0.0025, Train-L2-0.0525, Test-L2-0.0591\n",
      "Epoch-168, Time-45.7391, Train-MSE-0.0025, Train-L2-0.0525, Test-L2-0.0591\n",
      "Epoch-169, Time-45.9339, Train-MSE-0.0025, Train-L2-0.0524, Test-L2-0.0590\n",
      "Epoch-170, Time-45.6460, Train-MSE-0.0025, Train-L2-0.0524, Test-L2-0.0590\n",
      "Epoch-171, Time-45.5734, Train-MSE-0.0025, Train-L2-0.0524, Test-L2-0.0590\n",
      "Epoch-172, Time-45.8750, Train-MSE-0.0025, Train-L2-0.0524, Test-L2-0.0590\n",
      "Epoch-173, Time-45.9279, Train-MSE-0.0025, Train-L2-0.0524, Test-L2-0.0590\n",
      "Epoch-174, Time-45.8765, Train-MSE-0.0025, Train-L2-0.0523, Test-L2-0.0589\n",
      "Epoch-175, Time-47.3722, Train-MSE-0.0025, Train-L2-0.0523, Test-L2-0.0589\n",
      "Epoch-176, Time-46.5666, Train-MSE-0.0025, Train-L2-0.0523, Test-L2-0.0589\n",
      "Epoch-177, Time-46.4616, Train-MSE-0.0025, Train-L2-0.0523, Test-L2-0.0589\n",
      "Epoch-178, Time-46.1734, Train-MSE-0.0025, Train-L2-0.0523, Test-L2-0.0589\n",
      "Epoch-179, Time-46.1793, Train-MSE-0.0025, Train-L2-0.0522, Test-L2-0.0589\n",
      "Epoch-180, Time-46.3102, Train-MSE-0.0025, Train-L2-0.0522, Test-L2-0.0588\n",
      "Epoch-181, Time-46.5459, Train-MSE-0.0025, Train-L2-0.0522, Test-L2-0.0588\n",
      "Epoch-182, Time-46.9963, Train-MSE-0.0025, Train-L2-0.0522, Test-L2-0.0587\n",
      "Epoch-183, Time-46.7129, Train-MSE-0.0025, Train-L2-0.0522, Test-L2-0.0588\n",
      "Epoch-184, Time-46.5256, Train-MSE-0.0025, Train-L2-0.0522, Test-L2-0.0588\n",
      "Epoch-185, Time-45.9644, Train-MSE-0.0025, Train-L2-0.0522, Test-L2-0.0587\n",
      "Epoch-186, Time-46.1352, Train-MSE-0.0025, Train-L2-0.0521, Test-L2-0.0587\n",
      "Epoch-187, Time-46.6181, Train-MSE-0.0025, Train-L2-0.0522, Test-L2-0.0588\n",
      "Epoch-188, Time-46.3580, Train-MSE-0.0025, Train-L2-0.0522, Test-L2-0.0590\n",
      "Epoch-189, Time-46.0457, Train-MSE-0.0025, Train-L2-0.0521, Test-L2-0.0586\n",
      "Epoch-190, Time-46.0327, Train-MSE-0.0025, Train-L2-0.0520, Test-L2-0.0587\n",
      "Epoch-191, Time-46.2381, Train-MSE-0.0025, Train-L2-0.0520, Test-L2-0.0585\n",
      "Epoch-192, Time-46.0348, Train-MSE-0.0025, Train-L2-0.0520, Test-L2-0.0587\n",
      "Epoch-193, Time-46.5293, Train-MSE-0.0025, Train-L2-0.0519, Test-L2-0.0585\n",
      "Epoch-194, Time-46.8256, Train-MSE-0.0025, Train-L2-0.0519, Test-L2-0.0585\n",
      "Epoch-195, Time-46.4226, Train-MSE-0.0025, Train-L2-0.0520, Test-L2-0.0585\n",
      "Epoch-196, Time-46.1967, Train-MSE-0.0025, Train-L2-0.0518, Test-L2-0.0587\n",
      "Epoch-197, Time-46.1783, Train-MSE-0.0025, Train-L2-0.0520, Test-L2-0.0585\n",
      "Epoch-198, Time-46.1419, Train-MSE-0.0025, Train-L2-0.0519, Test-L2-0.0584\n",
      "Epoch-199, Time-46.0629, Train-MSE-0.0025, Train-L2-0.0519, Test-L2-0.0584\n",
      "Epoch-200, Time-46.1759, Train-MSE-0.0025, Train-L2-0.0515, Test-L2-0.0581\n",
      "Epoch-201, Time-46.0899, Train-MSE-0.0025, Train-L2-0.0515, Test-L2-0.0581\n",
      "Epoch-202, Time-46.2759, Train-MSE-0.0025, Train-L2-0.0515, Test-L2-0.0581\n",
      "Epoch-203, Time-46.8824, Train-MSE-0.0025, Train-L2-0.0515, Test-L2-0.0581\n",
      "Epoch-204, Time-47.0618, Train-MSE-0.0025, Train-L2-0.0514, Test-L2-0.0581\n",
      "Epoch-205, Time-46.3154, Train-MSE-0.0025, Train-L2-0.0514, Test-L2-0.0581\n",
      "Epoch-206, Time-46.1306, Train-MSE-0.0025, Train-L2-0.0514, Test-L2-0.0581\n",
      "Epoch-207, Time-46.3647, Train-MSE-0.0025, Train-L2-0.0514, Test-L2-0.0580\n",
      "Epoch-208, Time-46.3616, Train-MSE-0.0025, Train-L2-0.0514, Test-L2-0.0581\n",
      "Epoch-209, Time-46.5744, Train-MSE-0.0025, Train-L2-0.0514, Test-L2-0.0580\n",
      "Epoch-210, Time-46.0999, Train-MSE-0.0025, Train-L2-0.0514, Test-L2-0.0580\n",
      "Epoch-211, Time-45.8163, Train-MSE-0.0025, Train-L2-0.0514, Test-L2-0.0580\n",
      "Epoch-212, Time-46.0469, Train-MSE-0.0025, Train-L2-0.0513, Test-L2-0.0580\n",
      "Epoch-213, Time-46.0094, Train-MSE-0.0025, Train-L2-0.0513, Test-L2-0.0580\n",
      "Epoch-214, Time-46.2952, Train-MSE-0.0025, Train-L2-0.0513, Test-L2-0.0580\n",
      "Epoch-215, Time-46.0785, Train-MSE-0.0025, Train-L2-0.0513, Test-L2-0.0580\n",
      "Epoch-216, Time-46.3590, Train-MSE-0.0025, Train-L2-0.0513, Test-L2-0.0579\n",
      "Epoch-217, Time-46.7373, Train-MSE-0.0025, Train-L2-0.0513, Test-L2-0.0579\n",
      "Epoch-218, Time-46.8997, Train-MSE-0.0025, Train-L2-0.0513, Test-L2-0.0579\n",
      "Epoch-219, Time-46.6309, Train-MSE-0.0025, Train-L2-0.0513, Test-L2-0.0579\n",
      "Epoch-220, Time-45.9609, Train-MSE-0.0025, Train-L2-0.0513, Test-L2-0.0579\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch-221, Time-45.5599, Train-MSE-0.0025, Train-L2-0.0513, Test-L2-0.0579\n",
      "Epoch-222, Time-45.6566, Train-MSE-0.0025, Train-L2-0.0512, Test-L2-0.0579\n",
      "Epoch-223, Time-45.9161, Train-MSE-0.0025, Train-L2-0.0512, Test-L2-0.0579\n",
      "Epoch-224, Time-46.0138, Train-MSE-0.0025, Train-L2-0.0512, Test-L2-0.0579\n",
      "Epoch-225, Time-46.3778, Train-MSE-0.0025, Train-L2-0.0512, Test-L2-0.0578\n",
      "Epoch-226, Time-46.0432, Train-MSE-0.0025, Train-L2-0.0512, Test-L2-0.0578\n",
      "Epoch-227, Time-46.3127, Train-MSE-0.0025, Train-L2-0.0512, Test-L2-0.0578\n",
      "Epoch-228, Time-46.4111, Train-MSE-0.0025, Train-L2-0.0512, Test-L2-0.0578\n",
      "Epoch-229, Time-46.2192, Train-MSE-0.0025, Train-L2-0.0512, Test-L2-0.0578\n",
      "Epoch-230, Time-46.2868, Train-MSE-0.0025, Train-L2-0.0511, Test-L2-0.0578\n",
      "Epoch-231, Time-46.7315, Train-MSE-0.0025, Train-L2-0.0511, Test-L2-0.0579\n",
      "Epoch-232, Time-46.1585, Train-MSE-0.0025, Train-L2-0.0511, Test-L2-0.0578\n",
      "Epoch-233, Time-45.9007, Train-MSE-0.0025, Train-L2-0.0511, Test-L2-0.0577\n",
      "Epoch-234, Time-45.5012, Train-MSE-0.0025, Train-L2-0.0511, Test-L2-0.0577\n",
      "Epoch-235, Time-45.6187, Train-MSE-0.0025, Train-L2-0.0511, Test-L2-0.0577\n",
      "Epoch-236, Time-45.7295, Train-MSE-0.0025, Train-L2-0.0511, Test-L2-0.0577\n",
      "Epoch-237, Time-45.6526, Train-MSE-0.0025, Train-L2-0.0511, Test-L2-0.0577\n",
      "Epoch-238, Time-46.0494, Train-MSE-0.0025, Train-L2-0.0510, Test-L2-0.0577\n",
      "Epoch-239, Time-46.3979, Train-MSE-0.0025, Train-L2-0.0510, Test-L2-0.0576\n",
      "Epoch-240, Time-45.9617, Train-MSE-0.0025, Train-L2-0.0509, Test-L2-0.0575\n",
      "Epoch-241, Time-45.5526, Train-MSE-0.0025, Train-L2-0.0508, Test-L2-0.0575\n",
      "Epoch-242, Time-45.8650, Train-MSE-0.0025, Train-L2-0.0508, Test-L2-0.0575\n",
      "Epoch-243, Time-45.6395, Train-MSE-0.0025, Train-L2-0.0508, Test-L2-0.0575\n",
      "Epoch-244, Time-45.7193, Train-MSE-0.0025, Train-L2-0.0508, Test-L2-0.0575\n",
      "Epoch-245, Time-46.2620, Train-MSE-0.0025, Train-L2-0.0508, Test-L2-0.0575\n",
      "Epoch-246, Time-46.0947, Train-MSE-0.0025, Train-L2-0.0508, Test-L2-0.0575\n",
      "Epoch-247, Time-45.7707, Train-MSE-0.0025, Train-L2-0.0508, Test-L2-0.0575\n",
      "Epoch-248, Time-46.1274, Train-MSE-0.0025, Train-L2-0.0508, Test-L2-0.0575\n",
      "Epoch-249, Time-45.9134, Train-MSE-0.0025, Train-L2-0.0508, Test-L2-0.0575\n",
      "Epoch-250, Time-45.6764, Train-MSE-0.0025, Train-L2-0.0508, Test-L2-0.0575\n",
      "Epoch-251, Time-46.1083, Train-MSE-0.0025, Train-L2-0.0508, Test-L2-0.0575\n",
      "Epoch-252, Time-45.8257, Train-MSE-0.0025, Train-L2-0.0508, Test-L2-0.0575\n",
      "Epoch-253, Time-45.9566, Train-MSE-0.0025, Train-L2-0.0508, Test-L2-0.0575\n",
      "Epoch-254, Time-45.8844, Train-MSE-0.0025, Train-L2-0.0508, Test-L2-0.0574\n",
      "Epoch-255, Time-45.4963, Train-MSE-0.0025, Train-L2-0.0508, Test-L2-0.0574\n",
      "Epoch-256, Time-45.7656, Train-MSE-0.0025, Train-L2-0.0508, Test-L2-0.0574\n",
      "Epoch-257, Time-45.9606, Train-MSE-0.0025, Train-L2-0.0507, Test-L2-0.0574\n",
      "Epoch-258, Time-45.6926, Train-MSE-0.0025, Train-L2-0.0507, Test-L2-0.0574\n",
      "Epoch-259, Time-45.6023, Train-MSE-0.0025, Train-L2-0.0507, Test-L2-0.0574\n",
      "Epoch-260, Time-45.8518, Train-MSE-0.0025, Train-L2-0.0507, Test-L2-0.0574\n",
      "Epoch-261, Time-45.5345, Train-MSE-0.0025, Train-L2-0.0507, Test-L2-0.0574\n",
      "Epoch-262, Time-45.5350, Train-MSE-0.0025, Train-L2-0.0507, Test-L2-0.0574\n",
      "Epoch-263, Time-45.6208, Train-MSE-0.0025, Train-L2-0.0507, Test-L2-0.0574\n",
      "Epoch-264, Time-45.5680, Train-MSE-0.0025, Train-L2-0.0507, Test-L2-0.0574\n",
      "Epoch-265, Time-45.8840, Train-MSE-0.0025, Train-L2-0.0507, Test-L2-0.0574\n",
      "Epoch-266, Time-45.8527, Train-MSE-0.0025, Train-L2-0.0507, Test-L2-0.0574\n",
      "Epoch-267, Time-45.4724, Train-MSE-0.0025, Train-L2-0.0507, Test-L2-0.0574\n",
      "Epoch-268, Time-45.9108, Train-MSE-0.0025, Train-L2-0.0507, Test-L2-0.0573\n",
      "Epoch-269, Time-45.8360, Train-MSE-0.0025, Train-L2-0.0507, Test-L2-0.0574\n",
      "Epoch-270, Time-45.3739, Train-MSE-0.0025, Train-L2-0.0507, Test-L2-0.0573\n",
      "Epoch-271, Time-45.5568, Train-MSE-0.0025, Train-L2-0.0507, Test-L2-0.0573\n",
      "Epoch-272, Time-45.8502, Train-MSE-0.0025, Train-L2-0.0506, Test-L2-0.0573\n",
      "Epoch-273, Time-45.6422, Train-MSE-0.0025, Train-L2-0.0506, Test-L2-0.0573\n",
      "Epoch-274, Time-45.4131, Train-MSE-0.0025, Train-L2-0.0506, Test-L2-0.0573\n",
      "Epoch-275, Time-45.9439, Train-MSE-0.0025, Train-L2-0.0506, Test-L2-0.0573\n",
      "Epoch-276, Time-46.3292, Train-MSE-0.0025, Train-L2-0.0506, Test-L2-0.0573\n",
      "Epoch-277, Time-45.9693, Train-MSE-0.0025, Train-L2-0.0506, Test-L2-0.0573\n",
      "Epoch-278, Time-45.8526, Train-MSE-0.0025, Train-L2-0.0506, Test-L2-0.0573\n",
      "Epoch-279, Time-45.6207, Train-MSE-0.0025, Train-L2-0.0506, Test-L2-0.0573\n",
      "Epoch-280, Time-45.5160, Train-MSE-0.0025, Train-L2-0.0505, Test-L2-0.0572\n",
      "Epoch-281, Time-45.5024, Train-MSE-0.0025, Train-L2-0.0505, Test-L2-0.0572\n",
      "Epoch-282, Time-46.0017, Train-MSE-0.0025, Train-L2-0.0505, Test-L2-0.0572\n",
      "Epoch-283, Time-45.9012, Train-MSE-0.0025, Train-L2-0.0505, Test-L2-0.0572\n",
      "Epoch-284, Time-45.6024, Train-MSE-0.0025, Train-L2-0.0505, Test-L2-0.0572\n",
      "Epoch-285, Time-45.8901, Train-MSE-0.0025, Train-L2-0.0505, Test-L2-0.0572\n",
      "Epoch-286, Time-45.4398, Train-MSE-0.0025, Train-L2-0.0505, Test-L2-0.0572\n",
      "Epoch-287, Time-45.3799, Train-MSE-0.0025, Train-L2-0.0505, Test-L2-0.0572\n",
      "Epoch-288, Time-45.8031, Train-MSE-0.0025, Train-L2-0.0505, Test-L2-0.0572\n",
      "Epoch-289, Time-45.7301, Train-MSE-0.0025, Train-L2-0.0505, Test-L2-0.0572\n",
      "Epoch-290, Time-45.5736, Train-MSE-0.0025, Train-L2-0.0505, Test-L2-0.0572\n",
      "Epoch-291, Time-45.9776, Train-MSE-0.0025, Train-L2-0.0505, Test-L2-0.0572\n",
      "Epoch-292, Time-45.7803, Train-MSE-0.0025, Train-L2-0.0505, Test-L2-0.0572\n",
      "Epoch-293, Time-45.5883, Train-MSE-0.0025, Train-L2-0.0505, Test-L2-0.0572\n",
      "Epoch-294, Time-45.9594, Train-MSE-0.0025, Train-L2-0.0505, Test-L2-0.0571\n",
      "Epoch-295, Time-45.6500, Train-MSE-0.0025, Train-L2-0.0505, Test-L2-0.0571\n",
      "Epoch-296, Time-45.5757, Train-MSE-0.0025, Train-L2-0.0505, Test-L2-0.0572\n",
      "Epoch-297, Time-45.8072, Train-MSE-0.0025, Train-L2-0.0505, Test-L2-0.0572\n",
      "Epoch-298, Time-46.4327, Train-MSE-0.0025, Train-L2-0.0505, Test-L2-0.0571\n",
      "Epoch-299, Time-46.2129, Train-MSE-0.0025, Train-L2-0.0504, Test-L2-0.0571\n"
     ]
    }
   ],
   "source": [
    "# Train the MF-WNO model on MF-dataset\n",
    "\n",
    "myloss = LpLoss(size_average=False)\n",
    "for ep in range(epochs):\n",
    "    model_mf.train()\n",
    "    t1 = default_timer()\n",
    "    train_mse = 0\n",
    "    train_l2 = 0\n",
    "    for x, y in train_loader_mf:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        out = model_mf(x).reshape(x.shape[0], s, s)\n",
    "        \n",
    "        mse = F.mse_loss(out.view(x.shape[0], -1), y.view(x.shape[0], -1), reduction='mean')\n",
    "        loss = myloss(out.view(x.shape[0],-1), y.view(x.shape[0],-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_mse += mse.item()\n",
    "        train_l2 += loss.item()\n",
    "    \n",
    "    scheduler.step()\n",
    "    model_mf.eval()\n",
    "    test_l2 = 0.0\n",
    "    with torch.no_grad():\n",
    "        for x, y in test_loader_mf:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "\n",
    "            out = model_mf(x).reshape(x.shape[0], s, s)\n",
    "\n",
    "            test_l2 += myloss(out.view(x.shape[0], -1), y.view(x.shape[0], -1)).item()\n",
    "\n",
    "    train_mse /= len(train_loader_mf)\n",
    "    train_l2/= ntrain\n",
    "    test_l2 /= ntest\n",
    "    t2 = default_timer()\n",
    "    print('Epoch-{}, Time-{:0.4f}, Train-MSE-{:0.4f}, Train-L2-{:0.4f}, Test-L2-{:0.4f}'\n",
    "          .format(ep, t2-t1, train_mse, train_l2, test_l2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the MF-WNO model\n",
    "\n",
    "torch.save(model_mf, 'model/MF_WNO_AC2D_6000samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pCujdZ_PT4Vl"
   },
   "outputs": [],
   "source": [
    "# Prediction:\n",
    "pred_mf = [] \n",
    "with torch.no_grad():\n",
    "    index = 0\n",
    "    for x, y in test_loader_mf:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        out = model_mf(x).reshape(x.shape[0], s, s)\n",
    "        test_l2 = myloss(out.view(x.shape[0], -1), y.view(x.shape[0], -1)).item()\n",
    "        test_l2 /= x.shape[0]\n",
    "        print('Batch-{}, Test-L2-{:0.4f}'.format(index, test_l2))\n",
    "        \n",
    "        pred_mf.append(out.cpu())\n",
    "        index += 1\n",
    "\n",
    "pred_mf = torch.cat(( pred_mf ), dim=0 )\n",
    "\n",
    "print('Mean mse_hf-{}'.format(F.mse_loss(y_test_mf, pred_mf).item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F-ELXZMPT7K_"
   },
   "outputs": [],
   "source": [
    "# Add the residual operator to LF-dataset \n",
    "\n",
    "real_mf = y_test_mf + x_test_mf[..., 1]\n",
    "output_mf = pred_mf + x_test_mf[..., 1]\n",
    "\n",
    "real_mf_time = real_mf.reshape(20, 50, s, s)\n",
    "output_mf_time = output_mf.reshape(20, 50, s, s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(real_mf.shape, output_mf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wu0WJf6wT8lu"
   },
   "outputs": [],
   "source": [
    "mse_pred = F.mse_loss(output_mf, real_mf).item()\n",
    "mse_LF = F.mse_loss(real_mf, x_test_mf[..., 1])\n",
    "mse_residual = F.mse_loss(y_test_mf, pred_mf)\n",
    "\n",
    "print('MSE-Predicted solution-{:0.4f}, MSE-LF Data-{:0.4f}, MSE-Residual-{:0.4f}'\n",
    "      .format(mse_pred, mse_LF, mse_residual))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 10524,
     "status": "ok",
     "timestamp": 1680493128514,
     "user": {
      "displayName": "CSCCM IITD",
      "userId": "18000198353382878931"
     },
     "user_tz": 240
    },
    "id": "T6UkMuPyUTPP",
    "outputId": "00f7dee6-7808-4e25-cca1-cb4281dfd879"
   },
   "outputs": [],
   "source": [
    "fig4, axs = plt.subplots(nrows=3, ncols=5, figsize=(16, 6), facecolor='w', edgecolor='k')\n",
    "fig4.subplots_adjust(hspace=0.35, wspace=0.2)\n",
    "\n",
    "fig4.suptitle(f'Predictions MFWNO AC2d Size', fontsize=16)\n",
    "sample = 0\n",
    "index = 0 \n",
    "for i in range(50):\n",
    "    if i % 10 == 0:\n",
    "        im = axs[0, index].imshow(real_mf_time[sample, i, :, :], cmap='jet', vmin=-1, vmax=1)\n",
    "        plt.colorbar(im, ax=axs[0, index])\n",
    "        im = axs[1, index].imshow(output_mf_time[sample, i, :, :], cmap='jet', vmin=-1, vmax=1)\n",
    "        plt.colorbar(im, ax=axs[1, index])\n",
    "        im = axs[2, index].imshow(torch.abs(real_mf_time[sample, i, :, :] - output_mf_time[sample, i, :, :]),\n",
    "                                    cmap='jet')\n",
    "        plt.colorbar(im, ax=axs[2, index])\n",
    "        index += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ElUfPiIXy8s"
   },
   "source": [
    "# High Fidelity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RHcYiiunVyvk"
   },
   "outputs": [],
   "source": [
    "class WaveConv2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, level, size, wavelet):\n",
    "        super(WaveConv2d, self).__init__()\n",
    "\n",
    "        \"\"\"\n",
    "        2D Wavelet layer. It does DWT, linear transform, and Inverse dWT. \n",
    "        \"\"\"\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.level = level\n",
    "        self.wavelet = wavelet       \n",
    "        dummy_data = torch.randn( 1,1,*size )        \n",
    "        dwt_ = DWT(J=self.level, mode='symmetric', wave=self.wavelet)\n",
    "        mode_data, mode_coef = dwt_(dummy_data)\n",
    "        self.modes1 = mode_data.shape[-2]\n",
    "        self.modes2 = mode_data.shape[-1]\n",
    "        \n",
    "        # Parameter initilization\n",
    "        self.scale = (1 / (in_channels * out_channels))\n",
    "        self.weights1 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2))\n",
    "        self.weights2 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2))\n",
    "        self.weights3 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2))\n",
    "        self.weights4 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2))\n",
    "\n",
    "    # Convolution\n",
    "    def mul2d(self, input, weights):\n",
    "        # (batch, in_channel, x,y ), (in_channel, out_channel, x,y) -> (batch, out_channel, x,y)\n",
    "        return torch.einsum(\"bixy,ioxy->boxy\", input, weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Input parameters: \n",
    "        -----------------\n",
    "        x : tensor, shape-[Batch * Channel * x * y]\n",
    "        Output parameters: \n",
    "        ------------------\n",
    "        x : tensor, shape-[Batch * Channel * x * y]\n",
    "        \"\"\"\n",
    "        # Compute single tree Discrete Wavelet coefficients using some wavelet\n",
    "        dwt = DWT(J=self.level, mode='symmetric', wave=self.wavelet).to(x.device)\n",
    "        x_ft, x_coeff = dwt(x)\n",
    "\n",
    "        # Multiply the final approximate Wavelet modes\n",
    "        out_ft = self.mul2d(x_ft, self.weights1)\n",
    "        # Multiply the final detailed wavelet coefficients\n",
    "        x_coeff[-1][:,:,0,:,:] = self.mul2d(x_coeff[-1][:,:,0,:,:].clone(), self.weights2)\n",
    "        x_coeff[-1][:,:,1,:,:] = self.mul2d(x_coeff[-1][:,:,1,:,:].clone(), self.weights3)\n",
    "        x_coeff[-1][:,:,2,:,:] = self.mul2d(x_coeff[-1][:,:,2,:,:].clone(), self.weights4)\n",
    "        \n",
    "        # Return to physical space        \n",
    "        idwt = IDWT(mode='symmetric', wave=self.wavelet).to(x.device)\n",
    "        x = idwt((out_ft, x_coeff))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WNO2d(nn.Module):\n",
    "    def __init__(self, width, level, size, wavelet, in_channel, grid_range):\n",
    "        super(WNO2d, self).__init__()\n",
    "\n",
    "        self.level = level\n",
    "        self.width = width\n",
    "        self.size = size\n",
    "        self.wavelet = wavelet\n",
    "        self.in_channel = in_channel\n",
    "        self.grid_range = grid_range \n",
    "        self.padding = 1\n",
    "        \n",
    "        self.fc0 = nn.Linear(self.in_channel, self.width) # input channel is 3: (a(x, y), x, y)\n",
    "\n",
    "        self.conv0 = WaveConv2d(self.width, self.width, self.level, self.size, self.wavelet)\n",
    "        self.conv1 = WaveConv2d(self.width, self.width, self.level, self.size, self.wavelet)\n",
    "        self.conv2 = WaveConv2d(self.width, self.width, self.level, self.size, self.wavelet)\n",
    "        self.w0 = nn.Conv2d(self.width, self.width, 1)\n",
    "        self.w1 = nn.Conv2d(self.width, self.width, 1)\n",
    "        self.w2 = nn.Conv2d(self.width, self.width, 1)\n",
    "\n",
    "        self.fc1 = nn.Linear(self.width, 128)\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        grid = self.get_grid(x.shape, x.device)\n",
    "        x = torch.cat((x, grid), dim=-1)\n",
    "\n",
    "        x = self.fc0(x)\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "        if self.padding != 0:\n",
    "            x = F.pad(x, [0,self.padding, 0,self.padding]) \n",
    "        \n",
    "        # pdb.set_trace()\n",
    "        x1 = self.conv0(x)\n",
    "        x2 = self.w0(x)\n",
    "        x = x1 + x2\n",
    "        x = F.gelu(x)\n",
    "\n",
    "        x1 = self.conv1(x)\n",
    "        x2 = self.w1(x)\n",
    "        x = x1 + x2\n",
    "        x = F.gelu(x)\n",
    "\n",
    "        x1 = self.conv2(x)\n",
    "        x2 = self.w2(x)\n",
    "        x = x1 + x2\n",
    "\n",
    "        if self.padding != 0:\n",
    "            x = x[..., :-self.padding, :-self.padding]\n",
    "        x = x.permute(0, 2, 3, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.gelu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "    def get_grid(self, shape, device):\n",
    "        # The grid of the solution\n",
    "        batchsize, size_x, size_y = shape[0], shape[1], shape[2]\n",
    "        gridx = torch.tensor(np.linspace(0, self.grid_range[0], size_x), dtype=torch.float)\n",
    "        gridx = gridx.reshape(1, size_x, 1, 1).repeat([batchsize, 1, size_y, 1])\n",
    "        gridy = torch.tensor(np.linspace(0, self.grid_range[1], size_y), dtype=torch.float)\n",
    "        gridy = gridy.reshape(1, 1, size_y, 1).repeat([batchsize, size_x, 1, 1])\n",
    "        return torch.cat((gridx, gridy), dim=-1).to(device)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavelet = 'db4'  # wavelet basis function\n",
    "level = 2        # lavel of wavelet decomposition\n",
    "width = 32       # uplifting dimension\n",
    "s = side\n",
    "grid_range = [1, 1]\n",
    "in_channel = 3\n",
    "epochs = 105\n",
    "step_size = 20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5L-g7RCfWJ6q"
   },
   "outputs": [],
   "source": [
    "# Create the input and output (residual) dataset\n",
    "x_hf = torch.tensor( x_or_h, dtype=torch.float ) \n",
    "y_hf = torch.tensor( y_or_h, dtype=torch.float ) \n",
    "    \n",
    "generator_hf = torch.Generator().manual_seed(453)\n",
    "dataset_hf = torch.utils.data.random_split(torch.utils.data.TensorDataset(x_hf, y_hf),\n",
    "                                    [ntrain, ntest], generator=generator)\n",
    "train_data_hf, test_data_hf = dataset_hf[0], dataset_hf[1]\n",
    "\n",
    "# Split the training and testing datasets\n",
    "x_train_hf, y_train_hf = train_data_hf[:][0], train_data_hf[:][1]\n",
    "x_test_hf, y_test_hf = test_data_hf[:][0], test_data_hf[:][1]\n",
    "\n",
    "# Define the dataloaders\n",
    "train_loader_hf = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(x_train_hf, y_train_hf),\n",
    "                                             batch_size=batch_size, shuffle=True)\n",
    "test_loader_hf = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(x_test_hf, y_test_hf),\n",
    "                                            batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_hf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1680493159060,
     "user": {
      "displayName": "CSCCM IITD",
      "userId": "18000198353382878931"
     },
     "user_tz": 240
    },
    "id": "IT3OsJelW1S7",
    "outputId": "48fdf8da-302a-40d3-a2fd-9c4d7fb4b696"
   },
   "outputs": [],
   "source": [
    "model = WNO2d(width=width, level=level, size=[s,s], wavelet=wavelet,\n",
    "              in_channel=in_channel, grid_range=grid_range).to(device)\n",
    "print(count_params(model))\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-6)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 327910,
     "status": "ok",
     "timestamp": 1680493489523,
     "user": {
      "displayName": "CSCCM IITD",
      "userId": "18000198353382878931"
     },
     "user_tz": 240
    },
    "id": "tjg6qNVzW9Tb",
    "outputId": "449ca57a-432a-4aec-87c6-4f765373a68b",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train the HF-WNO model\n",
    "\n",
    "myloss = LpLoss(size_average=False)\n",
    "for ep in range(epochs):\n",
    "    model.train()\n",
    "    t1 = default_timer()\n",
    "    train_mse = 0\n",
    "    train_l2 = 0\n",
    "    for x, y in train_loader_hf:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        out = model(x).reshape(batch_size, s, s)\n",
    "        \n",
    "        mse = F.mse_loss(out.view(batch_size, -1), y.view(batch_size, -1), reduction='mean')\n",
    "        loss = myloss(out.view(batch_size,-1), y.view(batch_size,-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_mse += mse.item()\n",
    "        train_l2 += loss.item()\n",
    "    \n",
    "    scheduler.step()\n",
    "    model.eval()\n",
    "    test_l2 = 0.0\n",
    "    with torch.no_grad():\n",
    "        for x, y in test_loader_hf:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "\n",
    "            out = model(x).reshape(batch_size, s, s)\n",
    "\n",
    "            test_l2 += myloss(out.view(batch_size,-1), y.view(batch_size,-1)).item()\n",
    "\n",
    "    train_mse /= len(train_loader_hf)\n",
    "    train_l2/= ntrain\n",
    "    test_l2 /= ntest\n",
    "    t2 = default_timer()\n",
    "    print('Epoch-{}, Time-{:0.4f}, Train-MSE-{:0.4f}, Train-L2-{:0.4f}, Test-L2-{:0.4f}'\n",
    "          .format(ep, t2-t1, train_mse, train_l2, test_l2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the HF-WNO model\n",
    "\n",
    "torch.save(model, 'model/HF_WNO_AC2D_6000samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hI83wtdTTUbV"
   },
   "outputs": [],
   "source": [
    "# Predict on HF data using HF-WNO\n",
    "pred_hf = [] \n",
    "with torch.no_grad():\n",
    "    index = 0\n",
    "    for x, y in test_loader_hf:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        out = model(x).reshape(x.shape[0], s, s)\n",
    "        test_l2 = myloss(out.view(x.shape[0], -1), y.view(x.shape[0], -1)).item()\n",
    "        test_l2 /= x.shape[0]\n",
    "        print('Batch-{}, Test-L2-{:0.4f}'.format(index, test_l2))\n",
    "        \n",
    "        pred_hf.append(out.cpu())\n",
    "        index += 1\n",
    "\n",
    "pred_hf = torch.cat(( pred_hf ), dim=0 )\n",
    "\n",
    "print('Mean mse_hf-{}'.format(F.mse_loss(y_test_hf, pred_hf).item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_hf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_hf = pred_hf.reshape(20, 50, s, s)\n",
    "output_hf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_pred_hf = F.mse_loss(pred_hf, y_test_hf).item()\n",
    "\n",
    "print('MSE-Predicted solution-{:0.4f}'.format(mse_pred_hf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 314
    },
    "executionInfo": {
     "elapsed": 570,
     "status": "ok",
     "timestamp": 1680493504605,
     "user": {
      "displayName": "CSCCM IITD",
      "userId": "18000198353382878931"
     },
     "user_tz": 240
    },
    "id": "whU4jHaxT4UH",
    "outputId": "91947d56-1b36-433b-c7ee-fcf2e568727a"
   },
   "outputs": [],
   "source": [
    "fig5, axs = plt.subplots(nrows=3, ncols=5, figsize=(16, 6), facecolor='w', edgecolor='k')\n",
    "fig5.subplots_adjust(hspace=0.35, wspace=0.2)\n",
    "\n",
    "fig5.suptitle(f'Predictions MFWNO AC2d Size', fontsize=16)\n",
    "index = 0 \n",
    "for i in range(50):\n",
    "    if i % 10 == 0:\n",
    "        im = axs[0, index].imshow(y_test_hf[i, :, :], cmap='jet', vmin=-1, vmax=1)\n",
    "        plt.colorbar(im, ax=axs[0, index])\n",
    "        im = axs[1, index].imshow(pred_hf[i, :, :], cmap='jet', vmin=-1, vmax=1)\n",
    "        plt.colorbar(im, ax=axs[1, index])\n",
    "        im = axs[2, index].imshow(torch.abs(y_test_hf[i, :, :] - pred_hf[i, :, :]),\n",
    "                                    cmap='jet')\n",
    "        plt.colorbar(im, ax=axs[2, index])\n",
    "        index += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4QQDQa_Ugjef"
   },
   "outputs": [],
   "source": [
    "# Define rollout function for time-dependent prediction\n",
    "\n",
    "def rollout(model, vel_in, steps, device='cpu'):\n",
    "    with torch.no_grad():\n",
    "        vel = vel_in.to(device)\n",
    "        velocities = [vel.cpu().numpy()]\n",
    "        for _ in range(steps):\n",
    "            vel = model(vel) \n",
    "            velocities.append(vel.cpu().numpy())\n",
    "            \n",
    "    return np.concatenate(velocities,axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aOjrbBj0hARq"
   },
   "outputs": [],
   "source": [
    "# Load initial conditions and rollout the HF-time predictions\n",
    "\n",
    "u_pred = reader.read_field('uhr')[:100]\n",
    "u_init = torch.unsqueeze(u_pred[:,0,:,:],axis=-1)\n",
    "\n",
    "x = reader.read_field('x')\n",
    "y = reader.read_field('y')\n",
    "x_low = x.reshape(-1,)[::2]\n",
    "y_low = y.reshape(-1,)[::2]\n",
    "\n",
    "epsilon = reader.read_field('epsilon')\n",
    "time = reader.read_field('time')\n",
    "dt = float(reader.read_field('dtlarge'))\n",
    "\n",
    "nx = x_low.shape[0]\n",
    "ny = x_low.shape[0]\n",
    "dx= float(x_low[1]-x_low[0])\n",
    "dy = float(y_low[1]-y_low[0])\n",
    "\n",
    "trajectory_hf = rollout(model, u_init, 50, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1680493545834,
     "user": {
      "displayName": "CSCCM IITD",
      "userId": "18000198353382878931"
     },
     "user_tz": 240
    },
    "id": "1Q5UsXDNOGEG",
    "outputId": "fbb27683-53f6-4710-e7e4-9cba63277bcc"
   },
   "outputs": [],
   "source": [
    "trajectory_hf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uwiFOqpRwsYN"
   },
   "outputs": [],
   "source": [
    "def laplacian(x,y,dx,dy,epsilon,nx,ny):\n",
    "  kx = 2*torch.pi*torch.fft.fftfreq(x.shape[0],d=dx).cuda()\n",
    "  ky = 2*torch.pi*torch.fft.rfftfreq(y.shape[0],d=dy).cuda()\n",
    "  kxx,kyy = torch.meshgrid(kx,ky, indexing='ij')\n",
    "  kxx = kxx.reshape(1,nx,-1)\n",
    "  kyy = kyy.reshape(1,ny,-1)\n",
    "  lapl = -epsilon*(kxx**2+kyy**2)\n",
    "  return lapl\n",
    "\n",
    "def ac2d_solver(u,laplace,dt):\n",
    "  uhat = torch.fft.rfft2(u)\n",
    "  laplacian = laplace*uhat\n",
    "  u = u + dt*(torch.fft.irfft2(laplacian,s=(u.size(-2), u.size(-1))) + u - u**3)\n",
    "  return u\n",
    "\n",
    "def rollout_mf(model,solver,lapl,dt,vel_in,steps,device='cuda'):\n",
    "  with torch.no_grad():\n",
    "        vel = vel_in.to(device)\n",
    "        velocities = [vel.cpu().numpy()]\n",
    "        for _ in range(steps):\n",
    "          vel_low = torch.squeeze(vel[:,::2,::2,:])\n",
    "          vel_lout = ac2d_solver(vel_low,lapl,dt)\n",
    "          vel_loutup = F.interpolate(torch.unsqueeze(vel_lout,dim=1), \n",
    "                                     size=(vel.shape[1],vel.shape[2]), \n",
    "                                     mode='bicubic',align_corners=True).permute(0,2,3,1).to(device)\n",
    "          del vel_low\n",
    "          del vel_lout\n",
    "          vel_min = torch.concat((vel,vel_loutup),dim=-1)\n",
    "          del vel_loutup\n",
    "          vel = model(vel_min) \n",
    "          vel = vel + vel_min[:,:,:,1:]\n",
    "          del vel_min\n",
    "          velocities.append(vel.cpu().numpy())\n",
    "        \n",
    "  return np.concatenate(velocities,axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "__U4_tzSoGi0"
   },
   "outputs": [],
   "source": [
    "# Rollout the MF-time predictions\n",
    "\n",
    "lapl = laplacian(x_low,y_low,dx,dy,float(epsilon),nx,ny)\n",
    "trajectory_mf = rollout_mf(model_mf,ac2d_solver,lapl,dt,u_init,50,device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 810
    },
    "executionInfo": {
     "elapsed": 9337,
     "status": "ok",
     "timestamp": 1680496232322,
     "user": {
      "displayName": "CSCCM IITD",
      "userId": "18000198353382878931"
     },
     "user_tz": 240
    },
    "id": "HU6bi2-OU2zv",
    "outputId": "662c2668-34f7-440b-e98c-50c6164de9e9"
   },
   "outputs": [],
   "source": [
    "plt.rcParams[\"font.family\"] = \"Serif\"\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "fig6, ax = plt.subplots(nrows=5, ncols=6, figsize=(12, 10), dpi=300)\n",
    "# plt.subplots_adjust(hspace=0.25, wspace=0.3)\n",
    "\n",
    "sample = 0\n",
    "index = 0\n",
    "for i in range(50):\n",
    "    if i % 10 == 0:\n",
    "        im = ax[0,index].imshow(u_pred[sample,i,:,:], extent=[0,1,0,1], interpolation='Gaussian',\n",
    "                                vmin=-1, vmax=1, cmap='seismic')\n",
    "        plt.title('Ground Truth Time 5s');\n",
    "        plt.colorbar(im, ax=ax[0,index], orientation=\"horizontal\", fraction=0.04, pad=0.2)\n",
    "        im.set_clim(-1,1)\n",
    "        \n",
    "        im = ax[1,index].imshow(trajectory_hf[sample,:,:,i], extent=[0,1,0,1], interpolation='Gaussian',\n",
    "                                vmin=-1, vmax=1, cmap='seismic')\n",
    "        plt.title('HFSM-Time 5s');\n",
    "        plt.colorbar(im, ax=ax[1,index], orientation=\"horizontal\", fraction=0.04, pad=0.2)\n",
    "        \n",
    "        im = ax[2,index].imshow(np.abs(u_pred[sample,i,:,:] - trajectory_hf[sample,:,:,i]), extent=[0,1,0,1],\n",
    "                                interpolation='Gaussian', cmap='seismic')\n",
    "        plt.title('HFSM-Time 5s');\n",
    "        plt.colorbar(im, ax=ax[2,index], orientation=\"horizontal\", fraction=0.04, pad=0.2)\n",
    " \n",
    "        im = ax[3,index].imshow(trajectory_mf[sample,:,:,i], extent=[0,1,0,1], interpolation='Gaussian',\n",
    "                                vmin=-1, vmax=1, cmap='seismic')\n",
    "        plt.title('MFSM - Time 5s');\n",
    "        plt.colorbar(im, ax=ax[3,index], orientation=\"horizontal\", fraction=0.04, pad=0.2)\n",
    "        \n",
    "        im = ax[4,index].imshow(np.abs(u_pred[sample,i,:,:] - trajectory_mf[sample,:,:,i]), extent=[0,1,0,1],\n",
    "                                interpolation='Gaussian', cmap='seismic')\n",
    "        plt.title('MFSM - Time 5s');\n",
    "        plt.colorbar(im, ax=ax[4,index], orientation=\"horizontal\", fraction=0.04, pad=0.2)\n",
    "        index += 1\n",
    "        \n",
    "# figure1.savefig(f'predictions_allencahn_{ntrain_m}.png', format='png', dpi=300, bbox_inches='tight')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOjZCU0Za7/TgYeQCK7zD4/",
   "machine_shape": "hm",
   "provenance": [
    {
     "file_id": "1tX2GWAJczeMcQh_sQxxRE7l2iqTVgQiI",
     "timestamp": 1657707119891
    },
    {
     "file_id": "1dZDsY9GN11KWInJ5P2lGu5cjpube9Pyk",
     "timestamp": 1657558949607
    },
    {
     "file_id": "1Ms71XMkjtfE4Dk8XWfNwqcdRJpeWvC2Q",
     "timestamp": 1656413318405
    },
    {
     "file_id": "1fXGQRqGH0Sjj6hvnVQWF5aFAR7Kzbncs",
     "timestamp": 1656412090942
    },
    {
     "file_id": "1OPIb4ygLODwEKnHrahQ__DiDVyCq6543",
     "timestamp": 1656351883644
    }
   ]
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
